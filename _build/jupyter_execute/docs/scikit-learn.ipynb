{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn\n",
    "\n",
    "Scikit-learn is a popular open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection, model evaluation, and many other utilities.\n",
    "\n",
    "- Simple and efficient tools for predictive data analysis\n",
    "- Built on NumPy, SciPy, and matplotlib\n",
    "\n",
    "Scikit-learn provides dozens of built-in machine learning algorithms and models, called **estimators**. Each estimator can be fitted to some data using its fit method.\n",
    "\n",
    "Let's create some simple data with two classes (0 and 1) and 3 features to demonstrate the usage of some classification algorithms:\n",
    "\n",
    "class |feature 1 | feature 2 | feature 3\n",
    "--- | --- | --- | ---\n",
    "0 | 1 | 2 | 3\n",
    "1 | 11 | 12 | 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([1, 2, 3], 0), ([11, 12, 13], 1)]\n"
     ]
    }
   ],
   "source": [
    "# Create data\n",
    "\n",
    "X = [[ 1,  2,  3],  # 2 samples, 3 features\n",
    "     [11, 12, 13]]\n",
    "\n",
    "y = [0, 1]  # classes of each sample\n",
    "\n",
    "print(list(zip(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example where we fit a `RandomForestClassifier` to our very basic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0) # create estimator and call it clf\n",
    "clf.fit(X, y) # fit estimator to our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **fit** method generally accepts 2 inputs:\n",
    "\n",
    "The samples matrix (or design matrix) *X*:\n",
    "\n",
    "- The size of X is typically (n_samples, n_features)\n",
    "- samples are represented as rows and features are represented as columns.\n",
    "\n",
    "The target values *y* which are:\n",
    "\n",
    "- real numbers for regression tasks\n",
    "- integers for classification (or any other discrete set of values) \n",
    "- For unsupervized learning tasks, y does not need to be specified. \n",
    "\n",
    "y is usually 1d array where the i th entry corresponds to the target of the i th sample (row) of X.\n",
    "\n",
    "Both X and y are usually expected to be *numpy* arrays or equivalent array-like data types, though some estimators work with other formats such as sparse matrices.\n",
    "\n",
    "Once the estimator is fitted, it can be used for predicting target values of new data. You donâ€™t need to re-train the estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X)  # predict classes of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[4, 5, 6], [14, 15, 16]])  # predict classes of new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7 , 0.3 ],\n",
       "       [0.22, 0.78]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same procedure with different estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0)\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97545178, 0.02454822],\n",
       "       [0.02454858, 0.97545142]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important methods\n",
    "\n",
    "Given a scikit-learn estimator object, the following methods are available:\n",
    "\n",
    "Available in all estimators\n",
    "\n",
    "- `.fit()` : fit training data. For supervised learning applications, this accepts two arguments: the data X and the labels y (e.g. model.fit(X, y)). For unsupervised learning applications, this accepts only a single argument, the data X (e.g. model.fit(X)).\n",
    "\n",
    "Available in supervised estimators\n",
    "\n",
    "- `.predict()` : given a trained model, predict the label of a new set of data. This method accepts one argument, the new data X_new (e.g. model.predict(X_new)), and returns the learned label for each object in the array.\n",
    "\n",
    "- `.predict_proba()` : For classification problems, some estimators also provide this method, which returns the probability that a new observation has each categorical label. In this case, the label with the highest probability is returned by model.predict().\n",
    "\n",
    "- `.score()` : for classification or regression problems, most estimators implement a score method. Scores are between 0 and 1, with a larger score indicating a better fit.\n",
    "\n",
    "Available in unsupervised estimators\n",
    "\n",
    "- `.predict()` : predict labels in clustering algorithms.\n",
    "\n",
    "- `.transform()` : given an unsupervised model, transform new data into the new basis. This also accepts one argument X_new, and returns the new representation of the data based on the unsupervised model.\n",
    "\n",
    "- `model.fit_transform()` : some estimators implement this method, which more efficiently performs a fit and a transform on the same input data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}